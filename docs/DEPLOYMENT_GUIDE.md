# ğŸš€ PersonaPlex: GuÃ­a de Despliegue en Modal.com

Este documento resume el proceso de migraciÃ³n, los arreglos tÃ©cnicos realizados y cÃ³mo operar tu servidor de IA conversacional en Modal.

## ğŸ“‹ Resumen del Estado Actual
El sistema estÃ¡ **completamente operativo**. Hemos superado las limitaciones de memoria de Google Colab y los conflictos de dependencias de audio. La IA ahora responde en tiempo real a travÃ©s de WebSockets utilizando una GPU A100.

---

## ğŸ› ï¸ Lo que hemos arreglado

### 1. El Puente "Fiel" (ASGI Wrapper)
Hemos creado `modal_app.py` como un puente mÃ­nimo. 
- **InstalaciÃ³n Directa**: Modal instala tu carpeta `./moshi` como un paquete real (`pip install -e .`). Esto garantiza que se use **tu lÃ³gica** y no una versiÃ³n genÃ©rica.
- **TraducciÃ³n WebSocket**: Convierte el protocolo de Modal (ASGI) al formato que espera tu servidor, manteniendo la latencia bajo control.

### 2. El "Parche" de Audio (`sphn`)
Descubrimos que las versiones modernas de la librerÃ­a `sphn` borraban funciones esenciales.
- **SoluciÃ³n**: Hemos fijado la versiÃ³n `sphn==0.1.12` en `pyproject.toml` y `requirements.txt`. Esto restaura la capacidad de procesar audio Opus sin errores.

### 3. Estabilidad en GPU A100
Para evitar errores de memoria sincronizada ("RuntimeError: Can't call numpy on variable with grad"):
- **Torch No Grad**: Envolvemos el procesamiento en `torch.no_grad()`.
- **Detach**: Desasociamos los tensores antes de enviarlos al cliente para evitar bloqueos del motor.

---

## ğŸš€ GuÃ­a de OperaciÃ³n

### ConfiguraciÃ³n en una Nueva Cuenta de Modal
Si cambias de cuenta (ej. `modal token new`), debes recrear el entorno:

1. **Secreto de HuggingFace**:
   ```powershell
   modal secret create huggingface HF_TOKEN=tu_token_aqui
   ```
2. **Descargar Modelos**:
   ```powershell
   modal run modal_app.py::download_models
   ```
3. **Generar Voz de Pepper**:
   ```powershell
   modal run modal_app.py::generate_pepper_embedding
   ```

### CÃ³mo lanzar el servidor
Desde la terminal en `c:\Users\anls\code\KDFAST-AI\lab\personaplex-main`, ejecuta:
```powershell
modal serve modal_app.py
```
*Esto te darÃ¡ una URL (ej: `https://tu-usuario--ap-og-web.modal.run`). Ãšsala en tu frontend.*

### CÃ³mo actualizar tu cÃ³digo
Como usamos modo "editable" (`-e`), cualquier cambio que hagas en la carpeta `./moshi` se verÃ¡ reflejado en el servidor la prÃ³xima vez que lances el comando `modal serve`.

### GestiÃ³n de Voces (Embeddings)
Los modelos de voz se guardan en el volumen persistente `personaplex-weights` bajo `/root/weights`.

#### CÃ³mo generar la voz de Pepper
Si has aÃ±adido un nuevo archivo de audio (como `pepper.wav`) y quieres crear su "identidad" de voz:
1. AsegÃºrate de que el archivo `.wav` estÃ¡ en la raÃ­z del proyecto.
2. Ejecuta el comando de generaciÃ³n:
   ```powershell
   modal run modal_app.py::generate_pepper_embedding
   ```
   *Esto procesarÃ¡ el audio en una GPU A100 y guardarÃ¡ `pepper.pt` en el volumen de forma permanente.*

#### CÃ³mo usar nuevas voces
- **Servidor**: El sistema detecta automÃ¡ticamente si el `voice_prompt` termina en `.pt` y lo carga desde el volumen.
- **Cliente**: AÃ±ade la nueva opciÃ³n en `client/src/pages/Queue/Queue.tsx` (en el array `VOICE_OPTIONS`) para que aparezca en el desplegable.

---

## ğŸ’¡ Consejos para el Futuro
- **Voces**: Puedes aÃ±adir nuevos archivos `.pt` a la carpeta de voces y el sistema los detectarÃ¡ automÃ¡ticamente mediante el parÃ¡metro `voice_prompt` en la URL de conexiÃ³n.
- **Costes**: Modal solo te cobra mientras el servidor estÃ¡ encendido. Al cerrar la terminal (`Ctrl+C`), el servidor se apaga automÃ¡ticamente tras unos minutos de inactividad.

---

> [!IMPORTANT]
> El sistema es ahora 100% independiente. No dependes de scripts externos ni de versiones "inventadas". Es tu cÃ³digo, corriendo en la infraestructura mÃ¡s potente disponible.

modal deploy model_app.py  para deployar

Â¡Disfruta de la voz de PersonaPlex! ğŸ™ï¸âœ¨
