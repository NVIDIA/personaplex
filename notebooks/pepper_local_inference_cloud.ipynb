{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ‚òÅÔ∏è PersonaPlex Cloud: Modal-Ready Inference (Inside Out)\n",
                "\n",
                "This notebook is specifically configured to run on **Modal** using remote GPUs (A100/L4). \n",
                "\n",
                "**Features:**\n",
                "1. **Modal Volume Access**: Loads models and voices directly from `/root/weights`.\n",
                "2. **A100 Acceleration**: Runs high-speed inference without local hardware constraints.\n",
                "3. **Emotional System**: Includes the full *Inside Out* emotional prompting logic."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "import IPython.display as ipd\n",
                "import sys\n",
                "import asyncio\n",
                "import wave\n",
                "\n",
                "# Modal path adjustment\n",
                "sys.path.append(os.path.abspath('moshi'))\n",
                "\n",
                "from moshi.models import loaders\n",
                "from sentencepiece import SentencePieceProcessor\n",
                "from moshi.models.lm import LMGen\n",
                "\n",
                "print(\"‚úÖ Cloud Libraries loaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Cloud Model Initialization\n",
                "Loading models from the Modal persistent volume."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "weights_dir = Path('/root/weights') # Default Modal volume path\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "\n",
                "if not weights_dir.exists():\n",
                "    print(\"‚ö†Ô∏è Warning: /root/weights not found. If running locally, please change weights_dir to 'weights'.\")\n",
                "    weights_dir = Path('weights')\n",
                "\n",
                "print(f\"Loading models on {device} from {weights_dir}...\")\n",
                "\n",
                "mimi = loaders.get_mimi(weights_dir / loaders.MIMI_NAME, device)\n",
                "moshi_lm = loaders.get_moshi_lm(\n",
                "    weights_dir / loaders.MOSHI_NAME, \n",
                "    device=device,\n",
                "    cpu_offload=False # Cloud A100 has plenty of VRAM\n",
                ")\n",
                "\n",
                "tokenizer_path = weights_dir / loaders.TEXT_TOKENIZER_NAME\n",
                "text_tokenizer = SentencePieceProcessor(str(tokenizer_path))\n",
                "lm_gen = LMGen(moshi_lm, text_tokenizer)\n",
                "\n",
                "print(\"üöÄ Cloud System Ready.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Emotional Configuration\n",
                "Identical to local, ensures consistent behavior."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "EMOTIONS = {\n",
                "    \"Joy\": \"Hello! I'm so excited to talk to you! Hee-hee! Everything is wonderful! [laugh]\",\n",
                "    \"Sadness\": \"Hello... I'm feeling a bit down today. Everything seems so gray... [sigh]\",\n",
                "    \"Anger\": \"I can't believe it! This is unacceptable! Beep-boop-grrr! I'm very angry!\",\n",
                "    \"Fear\": \"What was that? I'm scared... are you there? Please don't go...\",\n",
                "    \"Disgust\": \"Ugh, how gross. That's repulsive. I don't even want to look at it. Puaj.\"\n",
                "}\n",
                "\n",
                "def wrap_with_system_tags(text):\n",
                "    return f\"(user) {text} (assistant)\"\n",
                "\n",
                "def get_emotional_prompt(emotion, user_text):\n",
                "    prefix = EMOTIONS.get(emotion, \"\")\n",
                "    return wrap_with_system_tags(f\"{prefix} {user_text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. High-Speed Cloud Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_audio_cloud(text, emotion=\"Joy\", voice_pt=\"/root/weights/pepper.pt\", output_wav=\"cloud_pepper_reply.wav\", duration_frames=300):\n",
                "    if os.path.exists(voice_pt):\n",
                "        lm_gen.load_voice_prompt_embeddings(voice_pt)\n",
                "        print(f\"‚úÖ Voice loaded from {voice_pt}\")\n",
                "    \n",
                "    emotional_text = get_emotional_prompt(emotion, text)\n",
                "    lm_gen.text_prompt_tokens = text_tokenizer.encode(emotional_text)\n",
                "    \n",
                "    print(f\"üé§ Generating cloud response for: {emotion}...\")\n",
                "    all_audio_chunks = []\n",
                "    \n",
                "    empty_audio_codes = torch.zeros((1, 8, 1), device=device, dtype=torch.long)\n",
                "    \n",
                "    for step in range(duration_frames):\n",
                "        tokens = lm_gen.step(moshi_tokens=empty_audio_codes)\n",
                "        if tokens is not None:\n",
                "            audio_tokens = tokens[:, 1:9]\n",
                "            pcm_chunk = mimi.decode(audio_tokens)\n",
                "            all_audio_chunks.append(pcm_chunk.cpu().numpy().flatten())\n",
                "\n",
                "    full_audio = np.concatenate(all_audio_chunks)\n",
                "    import scipy.io.wavfile as wavfile\n",
                "    wavfile.write(output_wav, 24000, (full_audio * 32767).astype(np.int16))\n",
                "    \n",
                "    print(f\"\\n‚ú® Cloud Generation Finished: {output_wav}\")\n",
                "    return output_wav\n",
                "\n",
                "# --- CLOUD TEST ---\n",
                "# generate_audio_cloud(\"Cloud Pepper, why are you so fast?\", emotion=\"Joy\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}