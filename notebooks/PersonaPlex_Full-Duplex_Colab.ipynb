{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertovalverde/PersonaPlex-Robot/blob/main/PersonaPlex_Machetero_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# PersonaPlex Full-Duplex Social Robot\n",
        "\n",
        "```\n",
        "    \n",
        "```\n",
        "\n",
        "**Cut through the noise.** Command Claude, Gemini, Realm, and shell with your voice.\n",
        "\n",
        "**Requirements:** HuggingFace token (free), A100 GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2"
      },
      "source": [
        "## Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-deps"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi --query-gpu=name,memory.total --format=csv\n",
        "print(\"\\n‚úÖ GPU ready!\")\n",
        "\n",
        "# System dependencies\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq libopus-dev portaudio19-dev ffmpeg > /dev/null 2>&1\n",
        "print(\"‚úÖ System deps installed\")\n",
        "\n",
        "# PersonaPlex Machetero\n",
        "!pip install -q git+https://github.com/chrisrijos/personaplex.git#subdirectory=moshi\n",
        "!pip install -q torchaudio\n",
        "print(\"‚úÖ Machetero installed\")\n",
        "\n",
        "# Cloudflare tunnel (faster than localtunnel)\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb > /dev/null 2>&1\n",
        "print(\"‚úÖ Cloudflare tunnel installed\")\n",
        "\n",
        "# HuggingFace token from Colab secrets\n",
        "# To set up: Click üîë (Secrets) in left sidebar ‚Üí Add \"HF_TOKEN\"\n",
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    print(\"‚úÖ HF token loaded from Colab secrets\")\n",
        "except:\n",
        "    from getpass import getpass\n",
        "    HF_TOKEN = getpass(\"Paste your HuggingFace token: \")\n",
        "    print(\"‚úÖ HF token set manually\")\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
        "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = HF_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4"
      },
      "source": [
        "## Step 2: Start Cloudflare Tunnel\n",
        "\n",
        "Creates a public URL for your Mac to connect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "start-tunnel"
      },
      "outputs": [],
      "source": [
        "import subprocess, re, time\n",
        "\n",
        "# Kill any existing tunnels\n",
        "!pkill -f cloudflared || true\n",
        "\n",
        "# Start Cloudflare tunnel\n",
        "proc = subprocess.Popen(\n",
        "    [\"cloudflared\", \"tunnel\", \"--url\", \"http://localhost:8998\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "print(\"Starting tunnel...\")\n",
        "tunnel_url = None\n",
        "for _ in range(30):\n",
        "    line = proc.stdout.readline()\n",
        "    if line:\n",
        "        match = re.search(r'https://[a-z0-9-]+\\.trycloudflare\\.com', line)\n",
        "        if match:\n",
        "            tunnel_url = match.group(0)\n",
        "            break\n",
        "    time.sleep(1)\n",
        "\n",
        "if tunnel_url:\n",
        "    ws_url = tunnel_url.replace(\"https://\", \"wss://\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"  üî• MACHETERO TUNNEL READY üî•\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nüåê URL: {ws_url}/api/chat\")\n",
        "    print(\"\\nüìã Run on your Mac:\")\n",
        "    print(f\"\\n   cd ~/Projects/personaplex\")\n",
        "    print(f\"   python -m moshi.remote_client --server {ws_url}/api/chat\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "else:\n",
        "    print(\"‚ùå Tunnel failed. Re-run this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5"
      },
      "source": [
        "## Step 5: Start Server\n",
        "\n",
        "**Keep this cell running!** First run downloads model (~14GB, 3-5 min).\n",
        "\n",
        "**Use headphones** to prevent audio feedback loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-server"
      },
      "outputs": [],
      "source": [
        "# Start Machetero server (no SSL - Cloudflare handles it)\n",
        "!python -m moshi.terminal_server \\\n",
        "    --host 0.0.0.0 \\\n",
        "    --port 8998 \\\n",
        "    --device cuda \\\n",
        "    --whisper-model base.en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reference"
      },
      "source": [
        "---\n",
        "\n",
        "## Voice Commands\n",
        "\n",
        "| Say This | Routes To |\n",
        "|----------|----------|\n",
        "| \"Claude, explain decorators\" | Claude Code CLI |\n",
        "| \"Hey Claude, fix this bug\" | Claude Code CLI |\n",
        "| \"Gemini, summarize this\" | Gemini CLI |\n",
        "| \"Realm sync\" | Realm CLI |\n",
        "| \"Run git status\" | Shell |\n",
        "| \"Execute npm test\" | Shell |\n",
        "| \"Help\" | System |\n",
        "| \"Quit\" | Exit |\n",
        "\n",
        "---\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "**Talking to itself:** Use headphones!\n",
        "\n",
        "**Connection refused:** Wait for \"Server running\" in Step 5, then re-run Step 4 for new URL.\n",
        "\n",
        "**Out of Memory:** Use A100 GPU (not T4).\n",
        "\n",
        "**Session disconnects:** Keep browser tab active. Re-run Steps 4 + 5."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
